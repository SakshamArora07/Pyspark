{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwcboObYF7Vg",
        "outputId": "90d4458f-8c7e-4772-de26-d1bd663821c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark py4j"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Step 1: Import necessary libraries\n",
        "# from pyspark.sql import SparkSession\n",
        "# from pyspark.ml.clustering import KMeans\n",
        "# from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# # Step 2: Initialize Spark session\n",
        "# spark = SparkSession.builder \\\n",
        "#     .appName(\"Anomaly Detection using KMeans\") \\\n",
        "#     .getOrCreate()\n",
        "\n",
        "# # Step 3: Load your data into a DataFrame\n",
        "# data = spark.read.csv(\"your_dataset.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# # Step 4: Prepare features\n",
        "# vector_assembler = VectorAssembler(inputCols=[\"feature1\", \"feature2\", ...], outputCol=\"features\")\n",
        "# data = vector_assembler.transform(data)\n",
        "\n",
        "# # Step 5: Train KMeans model\n",
        "# kmeans = KMeans(k=3, seed=123)  # You can adjust the number of clusters (k) as needed\n",
        "# model = kmeans.fit(data)\n",
        "\n",
        "# # Step 6: Assign clusters to data points\n",
        "# clustered_data = model.transform(data)\n",
        "\n",
        "# # Step 7: Calculate distance of each point to its nearest cluster center\n",
        "# # Euclidean distance is typically used here\n",
        "# distance_udf = F.udf(lambda features, center: float(features.squared_distance(center)), DoubleType())\n",
        "# clustered_data = clustered_data.withColumn(\"distance\", distance_udf(clustered_data[\"features\"], clustered_data[\"clusterCenter\"]))\n",
        "\n",
        "# # Step 8: Determine threshold for anomaly detection (e.g., based on percentile of distances)\n",
        "# threshold = clustered_data.approxQuantile(\"distance\", [0.99], 0.01)[0]\n",
        "\n",
        "# # Step 9: Identify anomalies\n",
        "# anomalies = clustered_data.filter(clustered_data[\"distance\"] > threshold)\n",
        "\n",
        "# # Step 10: Print or further analyze anomalies\n",
        "# anomalies.show()\n",
        "\n",
        "# # Step 11: Stop Spark session\n",
        "# spark.stop()\n"
      ],
      "metadata": {
        "id": "V759K070olbP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import col, avg\n",
        "from pyspark.context import SparkContext\n",
        "\n",
        "from pyspark.sql.types import DoubleType\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator"
      ],
      "metadata": {
        "id": "c8wR3KwkG2zD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.getOrCreate()\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "f67ZzAWKHe8t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.config(\"spark.driver.memory\", \"16g\").getOrCreate()"
      ],
      "metadata": {
        "id": "YYYf1LtlJoTR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"kmeans.csv\", header = True, inferSchema = True)\n",
        "df.show(10)"
      ],
      "metadata": {
        "id": "xK5oTfJfJ8_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd16e8e3-56d2-4ae7-c0ad-9568e875a03a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+---------+\n",
            "|                V1|       V2|\n",
            "+------------------+---------+\n",
            "|          2.072345|-3.241693|\n",
            "|          17.93671| 15.78481|\n",
            "|          1.083576| 7.319176|\n",
            "|          11.12067| 14.40678|\n",
            "|          23.71155| 2.557729|\n",
            "|24.169929999999997| 32.02478|\n",
            "|21.665779999999998| 4.892855|\n",
            "| 4.693683999999998| 12.34217|\n",
            "|          19.21191|-1.121366|\n",
            "|          4.230391|-4.441536|\n",
            "+------------------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "id": "7dakpRW2tqSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c17fa20d-c2bc-4a28-c4dc-b58678a04fc8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['V1', 'V2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colnames = [\"V1\", \"V2\"]\n"
      ],
      "metadata": {
        "id": "LdWBQcGWKKGp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(colnames)\n",
        "\n",
        "print(df.printSchema())"
      ],
      "metadata": {
        "id": "wxdNxsvfM2Bv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65183719-97fb-46e4-cda7-86a337b726a5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['V1', 'V2']\n",
            "root\n",
            " |-- V1: double (nullable = true)\n",
            " |-- V2: double (nullable = true)\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import DoubleType"
      ],
      "metadata": {
        "id": "24w35muHM-vo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.toDF(*colnames).withColumn(\"V2\", col(\"V2\").cast(DoubleType()))"
      ],
      "metadata": {
        "id": "YoEKc8bndZTh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.printSchema())"
      ],
      "metadata": {
        "id": "nrc6rmRAtfA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3038c966-19ec-4a2f-b4ab-9d057f78ccd8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- V1: double (nullable = true)\n",
            " |-- V2: double (nullable = true)\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.summary)"
      ],
      "metadata": {
        "id": "aXZG6PVXuDPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b4f9fa0-4d75-43c4-f236-395513e6c8ac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method DataFrame.summary of DataFrame[V1: double, V2: double]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.na.drop()"
      ],
      "metadata": {
        "id": "Rq1-SOvGlzM6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindata, testdata = data.randomSplit([0.9, 0.1])"
      ],
      "metadata": {
        "id": "uKkYwqWwxPsX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "vectorassembler = VectorAssembler(inputCols = colnames[:-1], outputCol = \"featureVector\")\n",
        "traindata = vectorassembler.transform(traindata)\n",
        "\n",
        "traindata.select(\"featureVector\").show()\n"
      ],
      "metadata": {
        "id": "lhSv1N8_xjLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a48ec79-4ee2-4905-aa70-7ff25c254c0b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|       featureVector|\n",
            "+--------------------+\n",
            "|         [-22.49599]|\n",
            "|         [-22.15215]|\n",
            "|         [-19.01791]|\n",
            "|          [-16.2653]|\n",
            "|         [-16.22395]|\n",
            "|[-14.947270000000...|\n",
            "|         [-14.69171]|\n",
            "|[-14.651420000000...|\n",
            "|         [-14.18104]|\n",
            "|         [-13.66531]|\n",
            "|         [-11.88057]|\n",
            "|[-11.706710000000...|\n",
            "|         [-11.54532]|\n",
            "|         [-11.53464]|\n",
            "|         [-11.45466]|\n",
            "|         [-10.77961]|\n",
            "|         [-10.59094]|\n",
            "|[-10.505139999999...|\n",
            "|         [-10.31962]|\n",
            "|[-9.467832000000001]|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler(inputCol = \"featureVector\", outputCol = \"scaledfeature\")\n",
        "scaler_model = scaler.fit(traindata)\n",
        "traindata = scaler_model.transform(traindata)"
      ],
      "metadata": {
        "id": "tD3lNMZpmEP7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.clustering import KMeans\n",
        "\n",
        "kmeans = KMeans(seed = 1234, k = 3,featuresCol = \"scaledfeature\")\n",
        "model = kmeans.fit(traindata)"
      ],
      "metadata": {
        "id": "HbYc6Xl8y2S_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "\n",
        "predictions = model.transform(traindata)\n",
        "evaluator=ClusteringEvaluator(featuresCol = \"scaledfeature\")"
      ],
      "metadata": {
        "id": "cgzsgDq_0AOn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette = evaluator.setMetricName(\"silhouette\").evaluate(predictions)"
      ],
      "metadata": {
        "id": "mLa0tJO50VYz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(silhouette)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmwULWVVWO5x",
        "outputId": "b8eaa355-b0b9-48be-f526-447a74df0a5b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7667664655512342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzt06F2CWR1K",
        "outputId": "90c7287e-3edb-41c3-a27f-b336d0c24f88"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------------------+--------------------+--------------------+----------+\n",
            "|                 V1|                 V2|       featureVector|       scaledfeature|prediction|\n",
            "+-------------------+-------------------+--------------------+--------------------+----------+\n",
            "|          -22.49599|0.13929160000000002|         [-22.49599]|[-0.8676284713542...|         0|\n",
            "|          -22.15215|           9.511638|         [-22.15215]|[-0.8543672024085...|         0|\n",
            "|          -19.01791|          0.6507304|         [-19.01791]|[-0.733485398137736]|         0|\n",
            "|           -16.2653|           13.90024|          [-16.2653]|[-0.627322352789014]|         0|\n",
            "|          -16.22395|           17.81785|         [-16.22395]|[-0.6257275602375...|         0|\n",
            "|-14.947270000000001|            16.5969|[-14.947270000000...|[-0.5764883884202...|         0|\n",
            "|          -14.69171| 31.799870000000002|         [-14.69171]|[-0.5666319147936...|         0|\n",
            "|-14.651420000000002|            10.9695|[-14.651420000000...|[-0.5650780044696...|         0|\n",
            "|          -14.18104|           1.871214|         [-14.18104]|[-0.5469363232030...|         0|\n",
            "|          -13.66531|           16.93903|         [-13.66531]|[-0.5270455768286...|         0|\n",
            "|          -11.88057|          0.1788024|         [-11.88057]|[-0.4582114762638...|         0|\n",
            "|-11.706710000000001|           8.073185|[-11.706710000000...|[-0.4515060196011...|         0|\n",
            "|          -11.54532|          -20.01888|         [-11.54532]|[-0.4452815076329...|         0|\n",
            "|          -11.53464|           11.63952|         [-11.53464]|[-0.444869599907427]|         0|\n",
            "|          -11.45466|  7.741682000000001|         [-11.45466]|[-0.4417849201427...|         0|\n",
            "|          -10.77961|           14.08271|         [-10.77961]|[-0.4157494978480...|         0|\n",
            "|          -10.59094| 15.402920000000002|         [-10.59094]|[-0.4084728470453...|         0|\n",
            "|-10.505139999999999| 20.750970000000002|[-10.505139999999...|[-0.4051637007112...|         0|\n",
            "|          -10.31962|           15.46054|         [-10.31962]|[-0.3980085395466...|         0|\n",
            "| -9.467832000000001| 0.6434593000000001|[-9.467832000000001]|[-0.3651566614849...|         0|\n",
            "+-------------------+-------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.show()"
      ],
      "metadata": {
        "id": "h2NAtNHqW74V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SUYvrzU4cyGL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}